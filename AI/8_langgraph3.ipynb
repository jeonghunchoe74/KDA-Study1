{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "727bf8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "default_model = os.getenv(\"OPENAI_DEFAULT_MODEL\")\n",
    "redis_host = os.getenv(\"REDIS_HOST\")\n",
    "redis_password = os.getenv(\"REDIS_PASSWORD\")\n",
    "redis_port = os.getenv(\"REDIS_PORT\")\n",
    "tavily_key = os.getenv(\"TAVILY_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c0e749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\edukd\\miniconda3\\envs\\myKDA2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated, List, Literal\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langgraph.types import interrupt, Command\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bca0f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(api_key=api_key, model_name=default_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c199c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a22daf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "def chatbot1(state: State):\n",
    "   # 가장 최근 메시지 가져오기\n",
    "    last_msg = state[\"messages\"][-1]\n",
    "    \n",
    "    # 메시지 내용에 \"도움\"이라는 단어가 있는지 확인\n",
    "    if \"도움\" in last_msg.content:\n",
    "        human_input = interrupt({\"query\": \"이 질문에 어떻게 답해야 할까요?\"})\n",
    "        response = AIMessage(content=human_input.get(\"data\", \"답변 없음\"))\n",
    "    else:        \n",
    "        llm_response = llm.invoke([last_msg])  # LLM의 메시지 생성\n",
    "        response = AIMessage(content=llm_response.content)\n",
    "    \n",
    "    return {\"messages\": [response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c05746f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"chatbot1\", chatbot1)\n",
    "\n",
    "workflow.add_edge(START, \"chatbot1\") \n",
    "workflow.add_edge(\"chatbot1\", END)    \n",
    "\n",
    "# MemorySaver: 메모리에 그래프 상태를 저장하는 checkpointer\n",
    "# checkpointer가 있어야 interrupt 후 재개가 가능함\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfd4fedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"thread_id\":\"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c606816a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain은 주로 자연어 처리(NLP) 애플리케이션을 구축하기 위한 프레임워크로, 특히 대화형 AI 및 언어 모델을 기반으로 한 시스템을 개발하는 데 도움을 주기 위해 설계되었습니다. 이 프레임워크는 텍스트 처리, 데이터 관리, 다양한 NLP 작업을 위한 여러 모듈과 구성 요소를 제공합니다.\n",
      "\n",
      "### 주요 특징 및 구성 요소:\n",
      "1. **모듈화**: LangChain은 다양한 구성 요소로 모듈화되어 있어 개발자가 필요에 따라 쉽게 추가하거나 변경할 수 있습니다.\n",
      "  \n",
      "2. **프롬프트 관리**: 언어 모델에 전달할 프롬프트를 쉽게 생성하고 관리할 수 있는 도구를 제공합니다. 이를 통해 사용자는 모델의 출력 형태나 내용에 맞게 프롬프트를 조정할 수 있습니다.\n",
      "\n",
      "3. **체인**: LangChain에서는 여러 작업을 연결하여 체인을 형성할 수 있습니다. 예를 들어, 데이터베이스에서 데이터를 가져오고, 이를 처리한 후, 언어 모델에 전달하는 과정이 하나의 체인으로 통합될 수 있습니다.\n",
      "\n",
      "4. **텍스트 생성**: 텍스트 생성 모델과의 통합이 용이하여, 대화형 인터페이스나 콘텐츠 생성 등에 활용할 수 있습니다.\n",
      "\n",
      "5. **유연한 백엔드**: 여러 개의 언어 모델 API와 통합 가능하여, OpenAI GPT, Hugging Face Transformers 등 다양한 모델을 사용할 수 있습니다.\n",
      "\n",
      "6. **검증 및 평가**: 모델의 응답을 검증하거나 평가하는 도구를 포함하여, 생성된 콘텐츠의 품질을 체크할 수 있는 기능도 제공합니다.\n",
      "\n",
      "### 적용 사례:\n",
      "- **챗봇**: 자연어 대화를 이해하고 적절한 응답을 생성하는 챗봇 구축.\n",
      "- **질문-답변 시스템**: 데이터베이스나 문서에서 정보를 가져와 질문에 대한 응답을 생성.\n",
      "- **콘텐츠 생성**: 블로그 포스트, 기사, 마케팅 자료 등의 자동 생성.\n",
      "\n",
      "LangChain은 대화형 AI 애플리케이션을 쉽게 구축하고 배포할 수 있도록 설계되어, 개발자들 사이에서 인기를 끌고 있습니다.\n",
      "{'messages': [HumanMessage(content='도움이 필요합니다 / LangChain에 대해 설명해줘', additional_kwargs={}, response_metadata={}), AIMessage(content='네, LangGraph는 훌륭한 선택입니다!', additional_kwargs={}, response_metadata={}), HumanMessage(content='Langchain에 대해 설명해줘', additional_kwargs={}, response_metadata={}), AIMessage(content='LangChain은 자연어 처리(NLP)와 대화형 AI 어플리케이션을 개발하기 위한 프레임워크입니다. 이 라이브러리는 다양한 언어 모델을 통합하고, 이러한 모델을 활용하여 복잡한 작업을 수행할 수 있도록 돕습니다. LangChain의 주요 특징은 다음과 같습니다:\\n\\n1. **체인 구성**: LangChain은 여러 개의 언어 모델 호출, 데이터 조회, API 통신 등을 체인 형태로 연결할 수 있는 구조를 제공합니다. 이를 통해 복잡한 업무 흐름을 간단하게 구성할 수 있습니다.\\n\\n2. **각종 데이터 소스 통합**: LangChain은 데이터베이스, API, 파일 시스템 등 다양한 데이터 소스와 쉽게 통합할 수 있습니다. 이를 통해 사용자 요구에 맞춰 데이터를 검색하고 활용하는 것이 가능합니다.\\n\\n3. **프롬프트 디자인**: LangChain은 프롬프트 템플릿을 사용하여 모델에 전달할 입력을 효율적으로 구성할 수 있도록 도와줍니다. 이를 통해 더욱 정교하고 효과적인 결과를 얻을 수 있습니다.\\n\\n4. **사용자 정의 도구**: 개발자는 자신의 필요에 맞는 도구를 만들고, 이를 Chain에 통합하여 커스터마이즈된 솔루션을 구축할 수 있습니다.\\n\\n5. **활발한 커뮤니티 및 문서화**: LangChain은 지속적으로 업데이트되고 있으며, 활발한 커뮤니티와 풍부한 문서화가 제공되어 있어 사용자들이 쉽게 접근하고 활용할 수 있도록 돕습니다.\\n\\nLangChain은 대화형 챗봇, 자동 응답 시스템, 데이터 분석 도구 등 다양한 애플리케이션을 만드는 데 유용합니다. 개발자들은 이 프레임워크를 통해 보다 빠르고 효율적으로 AI 기반 솔루션을 구축할 수 있습니다.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Langchain에 대해 설명해줘', additional_kwargs={}, response_metadata={}), AIMessage(content='LangChain은 주로 자연어 처리(NLP) 애플리케이션을 구축하기 위한 프레임워크로, 특히 대화형 AI 및 언어 모델을 기반으로 한 시스템을 개발하는 데 도움을 주기 위해 설계되었습니다. 이 프레임워크는 텍스트 처리, 데이터 관리, 다양한 NLP 작업을 위한 여러 모듈과 구성 요소를 제공합니다.\\n\\n### 주요 특징 및 구성 요소:\\n1. **모듈화**: LangChain은 다양한 구성 요소로 모듈화되어 있어 개발자가 필요에 따라 쉽게 추가하거나 변경할 수 있습니다.\\n  \\n2. **프롬프트 관리**: 언어 모델에 전달할 프롬프트를 쉽게 생성하고 관리할 수 있는 도구를 제공합니다. 이를 통해 사용자는 모델의 출력 형태나 내용에 맞게 프롬프트를 조정할 수 있습니다.\\n\\n3. **체인**: LangChain에서는 여러 작업을 연결하여 체인을 형성할 수 있습니다. 예를 들어, 데이터베이스에서 데이터를 가져오고, 이를 처리한 후, 언어 모델에 전달하는 과정이 하나의 체인으로 통합될 수 있습니다.\\n\\n4. **텍스트 생성**: 텍스트 생성 모델과의 통합이 용이하여, 대화형 인터페이스나 콘텐츠 생성 등에 활용할 수 있습니다.\\n\\n5. **유연한 백엔드**: 여러 개의 언어 모델 API와 통합 가능하여, OpenAI GPT, Hugging Face Transformers 등 다양한 모델을 사용할 수 있습니다.\\n\\n6. **검증 및 평가**: 모델의 응답을 검증하거나 평가하는 도구를 포함하여, 생성된 콘텐츠의 품질을 체크할 수 있는 기능도 제공합니다.\\n\\n### 적용 사례:\\n- **챗봇**: 자연어 대화를 이해하고 적절한 응답을 생성하는 챗봇 구축.\\n- **질문-답변 시스템**: 데이터베이스나 문서에서 정보를 가져와 질문에 대한 응답을 생성.\\n- **콘텐츠 생성**: 블로그 포스트, 기사, 마케팅 자료 등의 자동 생성.\\n\\nLangChain은 대화형 AI 애플리케이션을 쉽게 구축하고 배포할 수 있도록 설계되어, 개발자들 사이에서 인기를 끌고 있습니다.', additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "source": [
    "state = {\"messages\":[HumanMessage(content=\"Langchain에 대해 설명해줘\")]}\n",
    "result = graph.invoke(state,config)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb782da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실행 중단됨: False\n",
      "다음 노드()\n"
     ]
    }
   ],
   "source": [
    "state = graph.get_state(config)\n",
    "\n",
    "print(f\"실행 중단됨: {bool(state.next)}\")\n",
    "print(f\"다음 노드{state.next}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd817167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 첫 실행 ===\n",
      "실행 중단됨: True\n",
      "다음 노드: ('chatbot',)\n",
      "\n",
      "=== 인간 응답으로 재개 ===\n",
      "네, LangGraph는 훌륭한 선택입니다!\n",
      "최종 응답: 네, LangGraph는 훌륭한 선택입니다!\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import interrupt, Command\n",
    "from typing import TypedDict, Annotated, Literal\n",
    "from operator import add\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "# ============================================\n",
    "# 1. State 정의\n",
    "# ============================================\n",
    "class State(TypedDict):\n",
    "    \"\"\"그래프에서 사용할 상태 정의\n",
    "    messages: 대화 메시지 리스트\n",
    "    Annotated[list, add]: 새 메시지가 기존 리스트에 추가됨\n",
    "    \"\"\"\n",
    "    messages: Annotated[list, add]\n",
    "# ============================================\n",
    "# 2. 노드 함수 정의\n",
    "# ============================================\n",
    "def chatbot(state: State):\n",
    "    # 가장 최근 메시지 가져오기\n",
    "    last_msg = state[\"messages\"][-1]\n",
    "    # 메시지 내용에 \"도움\"이라는 단어가 있는지 확인\n",
    "    if \"도움\" in last_msg.content:\n",
    "        human_input = interrupt({\"query\": \"이 질문에 어떻게 답해야 할까요?\"})\n",
    "        response = AIMessage(content=human_input.get(\"data\", \"답변 없음\"))\n",
    "    else:\n",
    "        # ====== 수정 부분 시작 ======\n",
    "        # 여기에 LLM 호출 코드 추가 (llm은 이미 선언되어 있다고 가정)\n",
    "        llm_response = llm.invoke([last_msg])  # LLM의 메시지 생성\n",
    "        response = AIMessage(content=llm_response.content)\n",
    "    # 새 메시지를 상태에 추가 (Annotated[list, add]로 자동 병합됨)\n",
    "    print(response.content)\n",
    "    return {\"messages\": [response]}\n",
    "# ============================================\n",
    "# 3. 워크플로우 구성\n",
    "# ============================================\n",
    "# StateGraph 생성: State 타입을 사용하는 그래프\n",
    "workflow = StateGraph(State)\n",
    "# 노드 추가: \"chatbot\"이라는 이름으로 chatbot 함수 등록\n",
    "workflow.add_node(\"chatbot\", chatbot)\n",
    "# 엣지 추가: START -> chatbot -> END 순서로 실행\n",
    "workflow.add_edge(START, \"chatbot\")  # 시작점에서 chatbot으로\n",
    "workflow.add_edge(\"chatbot\", END)    # chatbot에서 종료점으로\n",
    "# ============================================\n",
    "# 4. 그래프 컴파일 (Checkpointer 필수!)\n",
    "# ============================================\n",
    "# MemorySaver: 메모리에 그래프 상태를 저장하는 checkpointer\n",
    "# checkpointer가 있어야 interrupt 후 재개가 가능함\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "# ============================================\n",
    "# 5. 그래프 실행\n",
    "# ============================================\n",
    "# config: 그래프 실행 설정\n",
    "# thread_id: 대화 세션을 구분하는 ID (같은 ID로 재개해야 함)\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "print(\"=== 첫 실행 ===\")\n",
    "# invoke: 그래프를 동기적으로 실행\n",
    "# HumanMessage: 사용자가 보낸 메시지\n",
    "# \"도움\"이 포함되어 있어서 interrupt가 발생할 것임\n",
    "#도움이 필요합니다 / LangChain에 대해 설명해줘\n",
    "result = graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"도움이 필요합니다 / LangChain에 대해 설명해줘\")]},\n",
    "    config\n",
    ")\n",
    "# ============================================\n",
    "# 6. 실행 상태 확인\n",
    "# ============================================\n",
    "# get_state: 현재 그래프의 상태 조회\n",
    "state = graph.get_state(config)\n",
    "# state.next: 다음에 실행될 노드 리스트\n",
    "# 비어있지 않으면 interrupt로 중단된 상태\n",
    "print(f\"실행 중단됨: {bool(state.next)}\")\n",
    "print(f\"다음 노드: {state.next}\")\n",
    "# ============================================\n",
    "# 7. Interrupt 재개 (인간 응답 제공)\n",
    "# ============================================\n",
    "# interrupt가 발생했는지 확인\n",
    "if state.next:\n",
    "    print(\"\\n=== 인간 응답으로 재개 ===\")\n",
    "    # 인간이 제공하는 실제 응답\n",
    "    human_response = \"네, LangGraph는 훌륭한 선택입니다!\"\n",
    "    # Command(resume=...): 중단된 지점에서 실행 재개\n",
    "    # resume 딕셔너리의 데이터가 interrupt()의 반환값이 됨\n",
    "    result = graph.invoke(\n",
    "        Command(resume={\"data\": human_response}),\n",
    "        config  # 같은 thread_id 사용!\n",
    "    )\n",
    "    # 최종 결과 출력\n",
    "    # messages[-1]: 가장 최근 메시지 (AI의 최종 응답)\n",
    "    print(f\"최종 응답: {result['messages'][-1].content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myKDA2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
